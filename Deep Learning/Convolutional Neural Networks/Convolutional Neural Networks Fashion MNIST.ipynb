{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks - Fashion MNIST\n",
    "<p>This is a dataset of fashion images. The categorization is given below </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0\tT-shirt/top\n",
    "\n",
    "1\tTrouser\n",
    "\n",
    "2\tPullover\n",
    "\n",
    "3\tDress\n",
    "\n",
    "4\tCoat\n",
    "\n",
    "5\tSandal\n",
    "\n",
    "6\tShirt\n",
    "\n",
    "7\tSneaker\n",
    "\n",
    "8\tBag\n",
    "\n",
    "9\tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f64c5e100d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[3], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128, \n",
    "                 kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128, \n",
    "                 kernel_size=3, \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D(pool_size = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation = 'relu')) # Fully connected layer 1\n",
    "model.add(Dense(64, activation = 'relu')) # Fully Connected Layer 2\n",
    "model.add(Dense(10, activation='softmax')) # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 128)       1280      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 13, 13, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 5, 5, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               409728    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 567,498\n",
      "Trainable params: 567,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 150s 80ms/step - loss: 0.4313 - accuracy: 0.8427 - val_loss: 0.3249 - val_accuracy: 0.8834\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 150s 80ms/step - loss: 0.2864 - accuracy: 0.8942 - val_loss: 0.2955 - val_accuracy: 0.8899\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 150s 80ms/step - loss: 0.2371 - accuracy: 0.9122 - val_loss: 0.2843 - val_accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f651991da10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = np.argmax(model.predict(X_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(model.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Confusion Matrix\n",
      "[[5726    1   27  108    9    5  114    0   10    0]\n",
      " [  14 5941    0   37    3    2    0    0    3    0]\n",
      " [ 205    2 5347   68  221    2  143    0   12    0]\n",
      " [  93   16   14 5754   95    1   25    0    2    0]\n",
      " [  14    6  554  210 5032    1  175    0    8    0]\n",
      " [   0    0    0    0    0 5967    0   21    0   12]\n",
      " [1183    5  442  195  384    1 3775    0   15    0]\n",
      " [   0    0    0    0    0   45    0 5809    0  146]\n",
      " [  10    0    3   11    7   31    7    2 5929    0]\n",
      " [   0    0    0    0    0   27    0  115    1 5857]]\n",
      "\n",
      "\n",
      " Training Set Accuracy 0.91895\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Confusion Matrix\")\n",
    "print(confusion_matrix(y_pred = y_train_pred, y_true=y_train))\n",
    "print(\"\\n\")\n",
    "print(f\" Training Set Accuracy {accuracy_score(y_pred = y_train_pred, y_true=y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Confusion Matrix\n",
      "[[939   0   8  18   2   2  28   0   3   0]\n",
      " [  5 978   0  13   1   0   1   0   2   0]\n",
      " [ 31   0 862  12  42   0  50   0   3   0]\n",
      " [ 17   6   5 947  13   0  12   0   0   0]\n",
      " [  1   0 112  43 802   0  39   0   3   0]\n",
      " [  0   0   0   0   0 990   0   7   0   3]\n",
      " [212   1  90  41  82   1 558   0  15   0]\n",
      " [  0   0   0   0   0  10   0 966   0  24]\n",
      " [  6   0   2   4   2  10   2   2 972   0]\n",
      " [  0   0   0   0   0  13   0  32   0 955]]\n",
      "\n",
      "\n",
      " Test Set Accuracy 0.8969\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set Confusion Matrix\")\n",
    "print(confusion_matrix(y_pred = y_test_pred, y_true=y_test))\n",
    "print(\"\\n\")\n",
    "print(f\" Test Set Accuracy {accuracy_score(y_pred = y_test_pred, y_true=y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
